{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3PTFvfpmCNj",
        "outputId": "85ffdcca-36fc-4dd6-b7c9-fef416204a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:  [100.00103811]\n",
            "2:  [99.38483513]\n",
            "3:  [98.77049741]\n",
            "4:  [98.18332178]\n",
            "5:  [97.62098704]\n",
            "6:  [97.06035449]\n",
            "7:  [96.50141899]\n",
            "8:  [95.95084112]\n",
            "9:  [95.40472118]\n",
            "10:  [94.86025434]\n",
            "11:  [94.31743563]\n",
            "12:  [93.7769885]\n",
            "13:  [93.24288983]\n",
            "14:  [92.71377268]\n",
            "15:  [92.1876888]\n",
            "16:  [91.66615924]\n",
            "17:  [91.15478786]\n",
            "18:  [90.64534795]\n",
            "19:  [90.14233692]\n",
            "20:  [89.651155]\n",
            "21:  [89.16578952]\n",
            "22:  [88.68617357]\n",
            "23:  [88.21363542]\n",
            "24:  [87.75275795]\n",
            "25:  [87.30501201]\n",
            "26:  [86.86772373]\n",
            "27:  [86.44199094]\n",
            "28:  [86.02984608]\n",
            "29:  [85.63180578]\n",
            "30:  [85.24257858]\n",
            "31:  [84.86165718]\n",
            "32:  [84.48770882]\n",
            "33:  [84.12004437]\n",
            "34:  [83.75827229]\n",
            "35:  [83.40106983]\n",
            "36:  [83.04972408]\n",
            "37:  [82.70439787]\n",
            "38:  [82.36096813]\n",
            "39:  [82.01972024]\n",
            "40:  [81.6813268]\n",
            "41:  [81.34913031]\n",
            "42:  [81.02209669]\n",
            "43:  [80.69772257]\n",
            "44:  [80.37531307]\n",
            "45:  [80.05866482]\n",
            "46:  [79.74629236]\n",
            "47:  [79.43621095]\n",
            "48:  [79.12884846]\n",
            "49:  [78.82335384]\n",
            "50:  [78.51878397]\n",
            "51:  [78.21696677]\n",
            "52:  [77.91798391]\n",
            "53:  [77.62486286]\n",
            "54:  [77.33398047]\n",
            "55:  [77.04817258]\n",
            "56:  [76.76696392]\n",
            "57:  [76.49031866]\n",
            "58:  [76.21572289]\n",
            "59:  [75.94336543]\n",
            "60:  [75.67777166]\n",
            "61:  [75.41601139]\n",
            "62:  [75.15706659]\n",
            "63:  [74.90136871]\n",
            "64:  [74.65001927]\n",
            "65:  [74.40241366]\n",
            "66:  [74.1615259]\n",
            "67:  [73.92731762]\n",
            "68:  [73.69736713]\n",
            "69:  [73.47113503]\n",
            "70:  [73.24759773]\n",
            "71:  [73.02705095]\n",
            "72:  [72.81038286]\n",
            "73:  [72.59846217]\n",
            "74:  [72.38772942]\n",
            "75:  [72.17983329]\n",
            "76:  [71.9755658]\n",
            "77:  [71.77548124]\n",
            "78:  [71.58048484]\n",
            "79:  [71.38836029]\n",
            "80:  [71.19860206]\n",
            "81:  [71.01170783]\n",
            "82:  [70.82682552]\n",
            "83:  [70.64528992]\n",
            "84:  [70.46898623]\n",
            "85:  [70.29778951]\n",
            "86:  [70.13051376]\n",
            "87:  [69.96780185]\n",
            "88:  [69.81136398]\n",
            "89:  [69.65807984]\n",
            "90:  [69.50803632]\n",
            "91:  [69.36304338]\n",
            "92:  [69.22063776]\n",
            "93:  [69.08197481]\n",
            "94:  [68.94568334]\n",
            "95:  [68.81250855]\n",
            "96:  [68.68169105]\n",
            "97:  [68.55434043]\n",
            "98:  [68.42940105]\n",
            "99:  [68.30730238]\n",
            "100:  [68.18876986]\n",
            "101:  [68.07472021]\n",
            "102:  [67.96303493]\n",
            "103:  [67.85383106]\n",
            "104:  [67.74830649]\n",
            "105:  [67.64676451]\n",
            "106:  [67.5474462]\n",
            "107:  [67.45182226]\n",
            "108:  [67.35869132]\n",
            "109:  [67.26761979]\n",
            "110:  [67.17780485]\n",
            "111:  [67.09106843]\n",
            "112:  [67.00751067]\n",
            "113:  [66.92788804]\n",
            "114:  [66.85120505]\n",
            "115:  [66.77891503]\n",
            "116:  [66.70783696]\n",
            "117:  [66.63977166]\n",
            "118:  [66.57687599]\n",
            "119:  [66.51735788]\n",
            "120:  [66.46077046]\n",
            "121:  [66.40623697]\n",
            "122:  [66.35274912]\n",
            "123:  [66.30130337]\n",
            "124:  [66.25094081]\n",
            "125:  [66.20181741]\n",
            "126:  [66.15535003]\n",
            "127:  [66.11115087]\n",
            "128:  [66.06959667]\n",
            "129:  [66.03062623]\n",
            "130:  [65.99406097]\n",
            "131:  [65.95942391]\n",
            "132:  [65.9279275]\n",
            "133:  [65.89866499]\n",
            "134:  [65.87201788]\n",
            "135:  [65.84639719]\n",
            "136:  [65.82324602]\n",
            "137:  [65.80271526]\n",
            "138:  [65.78500608]\n",
            "139:  [65.76948874]\n",
            "140:  [65.75550627]\n",
            "141:  [65.74306485]\n",
            "142:  [65.73333776]\n",
            "143:  [65.72492816]\n",
            "144:  [65.7170401]\n",
            "145:  [65.7100979]\n",
            "146:  [65.70408631]\n",
            "147:  [65.69990481]\n",
            "148:  [65.69826718]\n",
            "149:  [65.69797634]\n",
            "150:  [65.69852678]\n",
            "pred:  [61.60267973]\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "training_datalist =  []\n",
        "testing_datalist =  []\n",
        "output_datalist =  []\n",
        "\n",
        "training_dataset = []\n",
        "validation_dataset = []\n",
        "y = []\n",
        "y_val = []\n",
        "coefficient_output = []\n",
        "\n",
        "\n",
        "\n",
        "training_dataroot = 'data-1-year.csv'\n",
        "# testing_dataroot = 'hw1_advanced_testing.csv'\n",
        "# output_dataroot = 'hw1_advanced.csv'\n",
        "coefficient_output_dataroot = 'model_coefficient.csv'\n",
        "\n",
        "\n",
        "W = []\n",
        "B = []\n",
        "\n",
        "\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "  #print(training_datalist)\n",
        "\n",
        "#with open(testing_dataroot, newline='') as csvfile:\n",
        "#  testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "#  #print(testing_datalist)\n",
        "\n",
        "\n",
        "\n",
        "def SplitData():\n",
        "    global training_dataset, y, training_datalist\n",
        "    #print(len(training_datalist[0]))\n",
        "    y = np.array([[float(training_datalist[i][-1])] for i in range(1, len(training_datalist))])\n",
        "    for i in range(1, len(training_datalist)):\n",
        "        p = []\n",
        "        for j in range(len(training_datalist[i])-1):\n",
        "            p.append(float(training_datalist[i][j].replace(',','')))\n",
        "        training_dataset.append(p)\n",
        "    training_dataset = np.array(training_dataset)\n",
        "\n",
        "def PreprocessData():\n",
        "  global training_dataset, y\n",
        "  index = [1197]\n",
        "  training_dataset = np.delete(training_dataset, index, axis = 0)\n",
        "  y = np.delete(y, index, axis = 0)\n",
        "\n",
        "\n",
        "def train_val_split(X, y, val_size, random_state):\n",
        "    np.random.seed(random_state)\n",
        "    np.random.shuffle(X)\n",
        "    np.random.shuffle(y)\n",
        "\n",
        "    X_train = X[: int(len(X) - val_size)]\n",
        "    X_val = X[-int(val_size) :]\n",
        "\n",
        "    y_train = y[: int(len(y) - val_size)]\n",
        "    y_val = y[-int(val_size) :]\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "def GradientDescent():\n",
        "    global W, B, coefficient_output, training_dataset, y\n",
        "    W = np.random.randn(len(training_dataset[0]))\n",
        "    B = np.random.randn()\n",
        "    iter_num = 151\n",
        "    rate = 0.0000001\n",
        "    pred = []\n",
        "    for _ in range(1, iter_num):\n",
        "        pred = np.dot(training_dataset, W) + B\n",
        "        loss = np.mean((pred - y) ** 2)\n",
        "        gradient_w = np.dot(training_dataset.T, (pred - y)) / len(y)\n",
        "        gradient_b = np.mean(pred - y)\n",
        "        W -= rate * np.mean(gradient_w, axis=1)\n",
        "        B -= rate * gradient_b\n",
        "        #if _ % 10 == 0:\n",
        "        coefficient_output.append(np.concatenate((W, np.array([B]))))\n",
        "        print(f'{_}: ', sum(map(lambda x, z: abs((z-x)/z), pred, y))/len(y)*100)\n",
        "\n",
        "def MakePrediction():\n",
        "    global validation_dataset, W, B, y_val\n",
        "    pred = np.dot(validation_dataset, W) + B\n",
        "    print(f'pred: ', sum(map(lambda x, z: abs((z-x)/z), pred, y_val))/len(y_val)*100)\n",
        "    #print(output_datalist)\n",
        "\n",
        "SplitData()\n",
        "#print(len(y))\n",
        "PreprocessData()\n",
        "#print(training_dataset)\n",
        "#print(len(y))\n",
        "training_dataset, validation_dataset, y, y_val = train_val_split(training_dataset, y, 0.1 * len(y), 22)\n",
        "#print(len(training_dataset))\n",
        "#print(len(training_dataset[0]))\n",
        "GradientDescent()\n",
        "MakePrediction()\n",
        "\n",
        "'''\n",
        "output_datalist = list(map(lambda x: [x], output_datalist))\n",
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)\n",
        "'''\n",
        "\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in coefficient_output:\n",
        "    writer.writerow(row)\n",
        "\n"
      ]
    }
  ]
}