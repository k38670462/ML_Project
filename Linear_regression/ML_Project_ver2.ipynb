{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "R3PTFvfpmCNj",
        "outputId": "5e632c27-5a71-4b7a-c8f9-59f6bedc821e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[99681214.21436574 16640773.54152545  -166167.53629463   203289.91944605\n",
            "   3402472.09712144 -1320758.17328676  -637779.26368169   486833.48016364\n",
            "    430730.4710047   -625164.3004103    597459.99690872  -925801.76981114\n",
            "   1411308.36935345  2160467.14091906 -1628125.75535819 -1943649.75491404\n",
            "   2160467.14091888 -2802855.19384433  3150840.39039506  2160467.14091892\n",
            "   2160467.14091892  2160467.1409192  -2495972.95184417   322099.39124243]]\n",
            "Intercept: [-1.25194914e+10]\n",
            "Mean Squared Error: 74169734465835.02\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith open(coefficient_output_dataroot, \\'w\\', newline=\\'\\', encoding=\"utf-8\") as csvfile:\\n  writer = csv.writer(csvfile)\\n  for row in coefficient_output:\\n    writer.writerow(row)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "training_datalist =  []\n",
        "testing_datalist =  []\n",
        "output_datalist =  []\n",
        "training_dataset = []\n",
        "validation_dataset = []\n",
        "y = []\n",
        "y_val = []\n",
        "coefficient_output = []\n",
        "\n",
        "\n",
        "\n",
        "training_dataroot = 'data-1-year.csv'\n",
        "coefficient_output_dataroot = 'model_coefficient.csv'\n",
        "\n",
        "\n",
        "W = []\n",
        "B = []\n",
        "\n",
        "\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "  training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "  #print(training_datalist)\n",
        "\n",
        "#with open(testing_dataroot, newline='') as csvfile:\n",
        "#  testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "#  #print(testing_datalist)\n",
        "\n",
        "\n",
        "\n",
        "def SplitData():\n",
        "    global training_dataset, y, training_datalist\n",
        "    y = np.array([[float(training_datalist[i][-1])] for i in range(1, len(training_datalist))])\n",
        "    for i in range(1, len(training_datalist)):\n",
        "        p = []\n",
        "        for j in range(len(training_datalist[i])-1):\n",
        "            if training_datalist[i][j] == 'False':\n",
        "                p.append(float(0))\n",
        "            elif training_datalist[i][j] == 'True':\n",
        "                p.append(float(1))\n",
        "            else:\n",
        "                p.append(float(training_datalist[i][j].replace(',','')))\n",
        "        training_dataset.append(p)\n",
        "    training_dataset = np.array(training_dataset)\n",
        "\n",
        "def PreprocessData():\n",
        "  global training_dataset, y\n",
        "  index = [1197]\n",
        "  training_dataset = np.delete(training_dataset, index, axis = 0)\n",
        "  y = np.delete(y, index, axis = 0)\n",
        "\n",
        "\"\"\"\n",
        "def train_val_split(X, y, val_size, random_state):\n",
        "    np.random.seed(random_state)\n",
        "    np.random.shuffle(X)\n",
        "    np.random.shuffle(y)\n",
        "\n",
        "    X_train = X[: int(len(X) - val_size)]\n",
        "    X_val = X[-int(val_size) :]\n",
        "\n",
        "    y_train = y[: int(len(y) - val_size)]\n",
        "    y_val = y[-int(val_size) :]\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "def GradientDescent():\n",
        "    global W, B, coefficient_output, training_dataset, y\n",
        "    W = np.random.randn(len(training_dataset[0]))\n",
        "    B = np.random.randn()\n",
        "    iter_num = 151\n",
        "    rate = 0.0000001\n",
        "    pred = []\n",
        "    for _ in range(1, iter_num):\n",
        "        pred = np.dot(training_dataset, W) + B\n",
        "        loss = np.mean((pred - y) ** 2)\n",
        "        gradient_w = np.dot(training_dataset.T, (pred - y)) / len(y)\n",
        "        gradient_b = np.mean(pred - y)\n",
        "        W -= rate * np.mean(gradient_w, axis=1)\n",
        "        B -= rate * gradient_b\n",
        "        #if _ % 10 == 0:\n",
        "        coefficient_output.append(np.concatenate((W, np.array([B]))))\n",
        "        print(f'{_}: ', sum(map(lambda x, z: abs((z-x)/z), pred, y))/len(y)*100)\n",
        "\n",
        "def MakePrediction():\n",
        "    global validation_dataset, W, B, y_val\n",
        "    pred = np.dot(validation_dataset, W) + B\n",
        "    print(f'pred: ', sum(map(lambda x, z: abs((z-x)/z), pred, y_val))/len(y_val)*100)\n",
        "    #print(output_datalist)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "SplitData()\n",
        "# PreprocessData()\n",
        "# training_dataset, validation_dataset, y, y_val = train_val_split(training_dataset, y, 0.1 * len(y), 22)\n",
        "# GradientDescent()\n",
        "# MakePrediction()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(training_dataset, y, test_size=0.1, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "output_datalist = list(map(lambda x: [x], output_datalist))\n",
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in coefficient_output:\n",
        "    writer.writerow(row)\n",
        "\"\"\"\n"
      ]
    }
  ]
}