# -*- coding: utf-8 -*-


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import csv
import math
import random
import tensorflow as tf
from sklearn.metrics import r2_score


print(tf.__version__)
print(np.__version__)

np.random.seed(22)
tf.random.set_seed(22)

training_datalist =  []
testing_datalist =  []
output_datalist =  []
training_dataset = []
testing_dataset = []
validation_dataset = []
y = []
y_val = []
y_test = []
coefficient_output = []



training_dataroot = 'train-data-1-year.csv'
testing_dataroot = 'test-data-1-year.csv'
# coefficient_output_dataroot = 'model_coefficient.csv'

with open(training_dataroot, newline='') as csvfile:
  training_datalist = np.array(list(csv.reader(csvfile)))

with open(testing_dataroot, newline='') as csvfile:
  testing_datalist = np.array(list(csv.reader(csvfile)))


def SplitData():
    global training_dataset, y, training_datalist, testing_dataset, testing_datalist, y_test

    y = np.array([[float(training_datalist[i][-1])] for i in range(1, len(training_datalist))])
    y_test = np.array([[float(testing_datalist[i][-1])] for i in range(1, len(testing_datalist))])
    
    for i in range(1, len(training_datalist)):
        p = []
        for j in range(len(training_datalist[i])-1):
            if training_datalist[i][0] == 'longitude':
                pass
            elif training_datalist[i][j] == 'False' or training_datalist[i][j] == 'True' :
                #pass
                p.append(1. if training_datalist[i][j] == 'True' else 0.)
            else:
                p.append(float(training_datalist[i][j].replace(',','')))
        training_dataset.append(p)
    training_dataset = np.array(training_dataset)


    for i in range(1, len(testing_datalist)):
        p = []
        for j in range(len(testing_datalist[i])-1):
            if testing_datalist[i][0] == 'longitude':
                pass
            elif testing_datalist[i][j] == 'False' or testing_datalist[i][j] == 'True' :
                p.append(1. if testing_datalist[i][j] == 'True' else 0.)
            else:
                p.append(float(testing_datalist[i][j].replace(',','')))
        testing_dataset.append(p)
    testing_dataset = np.array(testing_dataset)


def train_val_split(X, y, val_size, random_state):
    np.random.seed(random_state)
    np.random.shuffle(X)
    np.random.shuffle(y)

    X_train = X[: int(len(X) - val_size)]
    X_val = X[-int(val_size) :]

    y_train = y[: int(len(y) - val_size)]
    y_val = y[-int(val_size) :]
    return X_train, X_val, y_train, y_val


def Training():
    global training_dataset, validation_dataset, y, y_val, testing_dataset, y_test
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=len(training_dataset[0],)),
        tf.keras.layers.Dense(1)
    ])

    #model.compile(tf.keras.optimizers.SGD(learning_rate=0.00001), loss='mse', metrics=[r2_score])
    model.compile(tf.keras.optimizers.SGD(learning_rate=0.0001), loss='mse')
    history = model.fit(training_dataset, y, validation_data=(validation_dataset, y_val), epochs=1000, verbose=0)
    #history = model.fit(training_dataset, y, epochs=100, verbose=0)
    trained_weights, trained_bias= model.layers[0].get_weights()

    print("Trained Weights:", trained_weights.flatten())
    print("Trained Bias:", trained_bias)

    plt.plot(history.history['loss'])
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.show()


    pred = model.predict(testing_dataset)
    print(f'mse: ', sum(map(lambda x, z: abs((z-x)/z), pred, y_val))/len(y_val)*100)
    print(f'r2 score: {r2_score(y_test, pred)}')


if __name__ == '__main__':
    SplitData()
    training_dataset, validation_dataset, y, y_val = train_val_split(training_dataset, y, 0.1 * len(y), 22)
    Training()


