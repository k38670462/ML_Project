{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBAUHkGnics6"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kj-clLA5ictF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.stats import randint\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV )\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    r2_score )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj6YDxqTictG"
      },
      "source": [
        "### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sfa-9IxXictG"
      },
      "outputs": [],
      "source": [
        "# random into interval\n",
        "# training,validation (early stopping), testing\n",
        "# validation tuning parameters\n",
        "\n",
        "AUTOMODE = True\n",
        "imputer = SimpleImputer(strategy='mean')   # deal with missing area\n",
        "\n",
        "train_file_path = '../data_processing/Unfiltered-Data/Train/train-data-10-year.csv'\n",
        "test_file_path = '../data_processing/Unfiltered-Data/Test/test-data-10-year.csv'\n",
        "train_df = pd.read_csv(train_file_path)\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "X_training, X_validation, Y_training, Y_validation = [], [], [], []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNQ3XtzictG"
      },
      "source": [
        "### Get Training and Validation Dataset\n",
        "- training: train model\n",
        "- validation: early stopping\n",
        "- testing: evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2r0Kug_kictH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] DataPreprocessing\n",
            "<class 'pandas.core.frame.DataFrame'> (38037, 24)\n",
            "<class 'pandas.core.series.Series'> (38037,)\n",
            "<class 'pandas.core.frame.DataFrame'> (16302, 24)\n",
            "<class 'pandas.core.series.Series'> (16302,)\n",
            "<class 'pandas.core.frame.DataFrame'> (6038, 24)\n",
            "<class 'pandas.core.series.Series'> (6038,)\n"
          ]
        }
      ],
      "source": [
        "def DataPreprocessing(train_df, test_df):\n",
        "    # Prepocess data frame, convert all elements to int/float type, deal with NaN value in area column.\n",
        "    train_df = train_df.apply(pd.to_numeric, errors='coerce')\n",
        "    train_df['area'] = imputer.fit_transform(train_df[['area']])\n",
        "\n",
        "    # Split data frame into feature set and label set, then seperate both into training and validation dataset.\n",
        "    features = train_df.drop('price', axis='columns')\n",
        "    label = train_df['price']\n",
        "\n",
        "    X_training, X_validation, Y_training, Y_validation = train_test_split(features, label, test_size=0.3, random_state=3)\n",
        "    X_testing = test_df.drop('price', axis='columns')\n",
        "    Y_testing = test_df['price']\n",
        "\n",
        "    # split training dataset into training and validation dataset, for early stopping\n",
        "    return X_training, X_validation, Y_training, Y_validation, X_testing, Y_testing\n",
        "\n",
        "X_training, X_validation, Y_training, Y_validation, X_testing, Y_testing = DataPreprocessing(train_df, test_df)\n",
        "print('[OK] DataPreprocessing')\n",
        "print(f'{type(X_training)} {X_training.shape}')\n",
        "print(f'{type(Y_training)} {Y_training.shape}')\n",
        "print(f'{type(X_validation)} {X_validation.shape}')\n",
        "print(f'{type(Y_validation)} {Y_validation.shape}')\n",
        "print(f'{type(X_testing)} {X_testing.shape}')\n",
        "print(f'{type(Y_testing)} {Y_testing.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters\n",
        "num_iterations = 50\n",
        "rf_parameters = {\n",
        "    'n_estimators': 167,\n",
        "    'criterion': 'entropy',\n",
        "    'max_depth': 14,\n",
        "    'min_samples_split': 3,\n",
        "    'min_samples_leaf': 1,\n",
        "    'max_features': 'sqrt',\n",
        "    'class_weight': 'balanced',\n",
        "    'random_state': 101,\n",
        "    'n_jobs': -1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Randomized Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END max_depth=14, min_samples_leaf=2, min_samples_split=2, n_estimators=173, random_state=142;, score=0.816 total time=  38.3s\n",
            "[CV 2/3] END max_depth=14, min_samples_leaf=2, min_samples_split=2, n_estimators=173, random_state=142;, score=0.812 total time=  37.0s\n",
            "[CV 3/3] END max_depth=14, min_samples_leaf=2, min_samples_split=2, n_estimators=173, random_state=142;, score=0.817 total time=  37.7s\n",
            "[CV 1/3] END max_depth=18, min_samples_leaf=3, min_samples_split=3, n_estimators=196, random_state=158;, score=0.824 total time=  48.7s\n",
            "[CV 2/3] END max_depth=18, min_samples_leaf=3, min_samples_split=3, n_estimators=196, random_state=158;, score=0.829 total time=  48.1s\n",
            "[CV 3/3] END max_depth=18, min_samples_leaf=3, min_samples_split=3, n_estimators=196, random_state=158;, score=0.827 total time=  48.8s\n",
            "[CV 1/3] END max_depth=17, min_samples_leaf=1, min_samples_split=2, n_estimators=181, random_state=189;, score=0.832 total time= 1.0min\n",
            "[CV 2/3] END max_depth=17, min_samples_leaf=1, min_samples_split=2, n_estimators=181, random_state=189;, score=0.819 total time= 1.0min\n",
            "[CV 3/3] END max_depth=17, min_samples_leaf=1, min_samples_split=2, n_estimators=181, random_state=189;, score=0.818 total time= 1.0min\n",
            "Best param in rCV: {'max_depth': 18, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 196, 'random_state': 158}\n",
            "Best score in rCV: 82.666\n"
          ]
        }
      ],
      "source": [
        "def AutoTuningRandomized(X_training, Y_training):\n",
        "    param = {\n",
        "        'n_estimators': randint(100, 200),\n",
        "        'max_depth': randint(10, 20),\n",
        "        'min_samples_split': randint(2, 5),\n",
        "        'min_samples_leaf': randint(1, 4),\n",
        "        'random_state': randint(100, 200),\n",
        "    }\n",
        "\n",
        "    # automatically search for best parameters and the corresponding score\n",
        "    result = RandomizedSearchCV (\n",
        "        RandomForestClassifier(),\n",
        "        param_distributions=param,\n",
        "        scoring='r2',\n",
        "        verbose=4,\n",
        "        cv=3,\n",
        "        n_iter=3\n",
        "    )\n",
        "\n",
        "    result.fit(X_training, Y_training)\n",
        "    best_param = result.best_params_\n",
        "    best_score = result.best_score_\n",
        "    print(f'Best param in rCV: {best_param}')\n",
        "    print(f'Best score in rCV: {round(best_score * 100, 3)}')\n",
        "\n",
        "    return best_param\n",
        "\n",
        "params_randomized = AutoTuningRandomized(X_training, Y_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=100, random_state=150;, score=0.824 total time=  25.5s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=100, random_state=150;, score=0.820 total time=  24.4s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=100, random_state=150;, score=0.813 total time=  24.5s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=105, random_state=150;, score=0.825 total time=  25.9s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=105, random_state=150;, score=0.822 total time=  25.6s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=105, random_state=150;, score=0.815 total time=  25.9s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=110, random_state=150;, score=0.827 total time=  27.1s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=110, random_state=150;, score=0.823 total time=  26.8s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=110, random_state=150;, score=0.817 total time=  27.3s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=115, random_state=150;, score=0.830 total time=  28.4s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=115, random_state=150;, score=0.824 total time=  28.5s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=115, random_state=150;, score=0.816 total time=  28.6s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=120, random_state=150;, score=0.828 total time=  29.9s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=120, random_state=150;, score=0.823 total time=  29.4s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=120, random_state=150;, score=0.815 total time=  29.8s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=125, random_state=150;, score=0.826 total time=  30.9s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=125, random_state=150;, score=0.824 total time=  30.8s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=125, random_state=150;, score=0.816 total time=  31.1s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=130, random_state=150;, score=0.826 total time=  32.2s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=130, random_state=150;, score=0.823 total time=  32.5s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=130, random_state=150;, score=0.817 total time=  32.5s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=135, random_state=150;, score=0.826 total time=  33.6s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=135, random_state=150;, score=0.823 total time=  34.1s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=135, random_state=150;, score=0.815 total time=  33.8s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=140, random_state=150;, score=0.827 total time=  35.0s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=140, random_state=150;, score=0.823 total time=  35.8s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=140, random_state=150;, score=0.818 total time=  35.3s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=145, random_state=150;, score=0.827 total time=  36.3s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=145, random_state=150;, score=0.824 total time=  37.3s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=145, random_state=150;, score=0.816 total time=  36.5s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=150, random_state=150;, score=0.826 total time=  38.0s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=150, random_state=150;, score=0.826 total time=  38.8s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=150, random_state=150;, score=0.818 total time=  39.1s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=155, random_state=150;, score=0.827 total time=  40.3s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=155, random_state=150;, score=0.826 total time=  40.4s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=155, random_state=150;, score=0.820 total time=  40.3s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=160, random_state=150;, score=0.825 total time=  41.8s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=160, random_state=150;, score=0.825 total time=  41.9s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=160, random_state=150;, score=0.818 total time=  41.9s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=165, random_state=150;, score=0.825 total time=  42.9s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=165, random_state=150;, score=0.824 total time=  43.1s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=165, random_state=150;, score=0.819 total time=  43.3s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=170, random_state=150;, score=0.829 total time=  44.4s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=170, random_state=150;, score=0.824 total time=  44.9s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=170, random_state=150;, score=0.822 total time=  44.7s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=175, random_state=150;, score=0.827 total time=  45.9s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=175, random_state=150;, score=0.824 total time=  45.7s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=175, random_state=150;, score=0.821 total time=  45.7s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=180, random_state=150;, score=0.830 total time=  46.7s\n",
            "[CV 2/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=180, random_state=150;, score=0.823 total time=  47.1s\n",
            "[CV 3/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=180, random_state=150;, score=0.822 total time=  47.1s\n",
            "[CV 1/3] END max_depth=16, min_samples_leaf=2, min_samples_split=3, n_estimators=185, random_state=150;, score=0.829 total time=  48.3s\n"
          ]
        }
      ],
      "source": [
        "def AutoTuningGrid(X_training, Y_training):\n",
        "\n",
        "    params = {\n",
        "        'n_estimators': list(range(100, 201, 5)),\n",
        "        'max_depth': [16],\n",
        "        'min_samples_split': [3],\n",
        "        'min_samples_leaf': [2],\n",
        "        'random_state': [150]\n",
        "    }\n",
        "\n",
        "    # params = {\n",
        "    #     'n_estimators': list(range(100, 201, 5)),\n",
        "    #     'max_depth': list(range(10, 21, 2)),\n",
        "    #     'min_samples_split': list(range(2, 5, 1)),\n",
        "    #     'min_samples_leaf': list(range(1, 4, 1)),\n",
        "    #     'random_state': list(range(100, 201, 5))\n",
        "    # }\n",
        "\n",
        "    result = GridSearchCV (\n",
        "        RandomForestClassifier(),\n",
        "        param_grid=params,\n",
        "        scoring='r2',\n",
        "        verbose=4,\n",
        "        cv=3\n",
        "    )\n",
        "\n",
        "    result.fit(X_training, Y_training)\n",
        "    best_param = result.best_params_\n",
        "    best_score = result.best_score_\n",
        "    print(f'Best param in gCV: {best_param}')\n",
        "    print(f'Best score in gCV: {round(best_score * 100, 3)}')\n",
        "\n",
        "    return best_param\n",
        "\n",
        "params_grid = AutoTuningGrid(X_training, Y_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkDzvPCpictJ"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kSS9MIxeictJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start building classifier ...\n",
            "[OK] Build classifier\n",
            "[OK] RandomForest\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def RandomForest(param, autoMode=False):\n",
        "\n",
        "\n",
        "    def RandomForestClassifier_aux(param):\n",
        "        classifier_auto = RandomForestClassifier(\n",
        "            n_estimators=param['n_estimators'],\n",
        "            criterion='entropy',\n",
        "            max_depth=param['max_depth'],\n",
        "            min_samples_split=param['min_samples_split'],\n",
        "            min_samples_leaf=param['min_samples_leaf'],\n",
        "            max_features='sqrt',\n",
        "            class_weight='balanced',\n",
        "            random_state=param['random_state'],\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        return classifier_auto\n",
        "    \n",
        "    \n",
        "    print('Start building classifier ...')\n",
        "    if autoMode is True:\n",
        "        classifier = RandomForestClassifier_aux(param)\n",
        "    else:   # manually\n",
        "        classifier = RandomForestClassifier(\n",
        "            n_estimators=131,\n",
        "            criterion='entropy',\n",
        "            max_depth=15,\n",
        "            min_samples_split=2,\n",
        "            min_samples_leaf=3,\n",
        "            max_features='sqrt',\n",
        "            class_weight='balanced',\n",
        "            random_state=156,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    print('[OK] Build classifier')\n",
        "\n",
        "    classifier.fit(X_training, Y_training)\n",
        "\n",
        "    return classifier\n",
        "\n",
        "classifier = RandomForest(params_grid, autoMode=AUTOMODE)\n",
        "print('[OK] RandomForest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Predictions and Print Out Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score: 59.305 %\n",
            "R2 score: 0.97076\n",
            "[OK] MakePredictions w/ training dataset\n"
          ]
        }
      ],
      "source": [
        "def MakePredictions(testing_dataset, classifier, validation_dataset=None):\n",
        "    predictions = classifier.predict(testing_dataset)\n",
        "\n",
        "    if validation_dataset is not None:\n",
        "        acc = round((accuracy_score(validation_dataset, predictions) * 100), 3)\n",
        "        r2 = r2_score(validation_dataset, predictions)\n",
        "        # output scores\n",
        "        print(f'Accuracy score: {acc} %')\n",
        "        print(f'R2 score: {round(r2, 5)}')\n",
        "\n",
        "    return predictions\n",
        "\n",
        "print('--- Training Dataset ---')\n",
        "Y_predictions_training = MakePredictions(X_training, classifier, Y_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obI5QK3xw-x5",
        "outputId": "1f1bf1d0-6c54-4c4d-d01d-df6f6be25762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score: 2.613 %\n",
            "R2 score: 0.79819\n",
            "[OK] MakePredictions w/ validation dataset\n"
          ]
        }
      ],
      "source": [
        "print('--- Validation Dataset ---')\n",
        "Y_predictions_validation = MakePredictions(X_validation, classifier, Y_validation)\n",
        "print()\n",
        "print('--- Testing Dataset ---')\n",
        "Y_predictions_testing = MakePredictions(X_testing, classifier, Y_testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
